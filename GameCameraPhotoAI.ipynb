{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "13G2f7DN5H08V7vLb5F3LnlRCXEthox8v",
      "authorship_tag": "ABX9TyO0TNYIQLr1YJv8UuA/UQPb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coltonro/Pytorch-Train-Model/blob/main/GameCameraPhotoAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2UmSIV_YdfOW",
        "outputId": "83696eb8-38f4-4268-8de3-9a5163888809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.102)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement xml-to-yolo (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for xml-to-yolo\u001b[0m\u001b[31m\n",
            "\u001b[0mCurrent working directory: /content\n",
            "YOLOv8 default save directory not found.\n",
            "Model object not found in memory.\n",
            "No .pt files found.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-495bae77cf2f>\u001b[0m in \u001b[0;36m<cell line: 106>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Convert and save annotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mconvert_xml_to_yolo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# Create dataset.yaml file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-495bae77cf2f>\u001b[0m in \u001b[0;36mconvert_xml_to_yolo\u001b[0;34m(xml_file, output_dir, image_width, image_height)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Function to convert XML to YOLO format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_xml_to_yolo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1138\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \"\"\"\n\u001b[1;32m   1221\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    578\u001b[0m                     \u001b[0;31m# It can be used to parse the whole source without feeding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                     \u001b[0;31m# it with chunks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_whole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Custom YOLOv8n Training for Animal Detection\n",
        "\n",
        "## Setup and Installation\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install ultralytics\n",
        "!pip install xml-to-yolo\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import torch\n",
        "from xml.etree import ElementTree as ET\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "# Set paths\n",
        "data_dir = '/content/drive/MyDrive/GameCameraPhotoAI_Training/master_training_folder_05-04-24'  # Update this path to your folder containing both images and XML files\n",
        "output_dir = os.path.join(data_dir, 'yolo_dataset')\n",
        "best_model_path = os.path.join(output_dir, 'best_model.pt')\n",
        "\n",
        "# Create YOLO dataset structure\n",
        "os.makedirs(os.path.join(output_dir, 'images', 'train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'images', 'val'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'images', 'test'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'labels', 'train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'labels', 'val'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'labels', 'test'), exist_ok=True)\n",
        "\n",
        "# Define classes\n",
        "classes = ['blue_jay', 'house_sparrow', 'northern_cardinal', 'white_winged_dove', 'black_vulture',\n",
        "           'lesser_goldfinch', 'european_starling', 'golden_fronted_woodpecker', 'northern_mockingbird',\n",
        "           'black_crested_titmouse', 'yellow_billed_cuckoo', 'carolina_wren', 'cat', 'deer', 'squirrel',\n",
        "           'person', 'raccoon', 'skunk', 'opossum', 'fox']\n",
        "\n",
        "# Function to convert XML to YOLO format\n",
        "def convert_xml_to_yolo(xml_file, output_dir, image_width=1138, image_height=640):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    yolo_lines = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        if class_name not in classes:\n",
        "            continue\n",
        "        class_id = classes.index(class_name)\n",
        "\n",
        "        bndbox = obj.find('bndbox')\n",
        "        xmin = float(bndbox.find('xmin').text)\n",
        "        ymin = float(bndbox.find('ymin').text)\n",
        "        xmax = float(bndbox.find('xmax').text)\n",
        "        ymax = float(bndbox.find('ymax').text)\n",
        "\n",
        "        # Convert to YOLO format\n",
        "        x_center = (xmin + xmax) / (2 * image_width)\n",
        "        y_center = (ymin + ymax) / (2 * image_height)\n",
        "        width = (xmax - xmin) / image_width\n",
        "        height = (ymax - ymin) / image_height\n",
        "\n",
        "        yolo_lines.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
        "\n",
        "    # Write YOLO format to file\n",
        "    base_name = os.path.splitext(os.path.basename(xml_file))[0]\n",
        "    with open(os.path.join(output_dir, f\"{base_name}.txt\"), 'w') as f:\n",
        "        f.write(\"\\n\".join(yolo_lines))\n",
        "\n",
        "# Convert annotations and split dataset\n",
        "image_files = [f for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
        "random.shuffle(image_files)\n",
        "\n",
        "train_files, test_val_files = train_test_split(image_files, test_size=0.4, random_state=42)\n",
        "val_files, test_files = train_test_split(test_val_files, test_size=0.5, random_state=42)\n",
        "\n",
        "for img_file in image_files:\n",
        "    xml_file = os.path.join(data_dir, img_file.replace('.jpg', '.xml'))\n",
        "    if os.path.exists(xml_file):\n",
        "        if img_file in train_files:\n",
        "            subset = 'train'\n",
        "        elif img_file in val_files:\n",
        "            subset = 'val'\n",
        "        else:\n",
        "            subset = 'test'\n",
        "\n",
        "        # Copy image\n",
        "        shutil.copy(os.path.join(data_dir, img_file),\n",
        "                    os.path.join(output_dir, 'images', subset, img_file))\n",
        "\n",
        "        # Convert and save annotation\n",
        "        convert_xml_to_yolo(xml_file, os.path.join(output_dir, 'labels', subset))\n",
        "\n",
        "# Create dataset.yaml file\n",
        "yaml_content = f\"\"\"\n",
        "train: {os.path.join(output_dir, 'images', 'train')}\n",
        "val: {os.path.join(output_dir, 'images', 'val')}\n",
        "test: {os.path.join(output_dir, 'images', 'test')}\n",
        "\n",
        "nc: {len(classes)}\n",
        "names: {classes}\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(output_dir, 'dataset.yaml'), 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "## Model Training\n",
        "\n",
        "# Check if CUDA is available\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU being used: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "\n",
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load a pretrained YOLOv8n model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "    data=os.path.join(output_dir, 'dataset.yaml'),\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    patience=20,\n",
        "    batch=64,\n",
        "    lr0=0.01,\n",
        "    device=0,\n",
        "    project=output_dir,\n",
        "    name='best_colab_9_26_24',\n",
        "    save=True,  # Save best model after each epoch\n",
        "    save_period=1,  # Save checkpoint every epoch\n",
        "    exist_ok=True  # Overwrite existing files\n",
        ")\n",
        "\n",
        "# After training, copy the best model to a specific location\n",
        "best_model = max(results.save_dir.glob('*.pt'), key=os.path.getctime)\n",
        "os.replace(best_model, best_model_path)\n",
        "print(f\"Best model saved to: {best_model_path}\")\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.val()\n",
        "\n",
        "print(f\"mAP@0.5: {results.box.map50}\")\n",
        "print(f\"mAP@0.5:0.95: {results.box.map}\")\n",
        "\n",
        "## Inference\n",
        "\n",
        "# Perform inference on a test image\n",
        "test_image = os.path.join(output_dir, 'images', 'test', random.choice(test_files))\n",
        "results = model(test_image)\n",
        "\n",
        "# Display results\n",
        "results[0].plot()\n",
        "\n",
        "# Save the trained model\n",
        "model.save('best_colab_9_26_24.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aSyrecYe2ssA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}